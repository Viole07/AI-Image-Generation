# ğŸ§  AI Image Generation with RTX Acceleration ğŸ¨

This project lets you generate high-quality AI images using your **own GPU (e.g., RTX 3050)** via a local **Stable Diffusion backend** powered by FastAPI + Diffusers, and a beautiful React + Vite frontend.

---

## âœ¨ Features

- ğŸ”¥ GPU-accelerated image generation (via PyTorch + CUDA)
- ğŸ¨ React frontend with prompt input and live preview
- âš¡ Powered by [HuggingFace Diffusers](https://huggingface.co/docs/diffusers)
- ğŸ“¡ Frontend-backend communication via FastAPI and REST
- ğŸŒ— Clean light/dark mode-friendly UI (optional)

---

## ğŸ“¦ Folder Structure

```
AI-IMAGE-GENERATION
â”œâ”€â”€ ai-image-frontend/      # React frontend (Vite)
â”‚   â”œâ”€â”€ src/components/
â”‚   â”‚   â””â”€â”€ ImageGenerator.jsx/css
â”‚   â””â”€â”€ .env                # API URL
â”œâ”€â”€ main.py                 # FastAPI backend w/ Stable Diffusion
â”œâ”€â”€ venv/                   # Python virtual environment (excluded)
â”œâ”€â”€ generated_image.png     # Output (optional)
â””â”€â”€ .env                    # Backend config (model, CORS)
```

---

## âš™ï¸ Backend Setup (FastAPI)

### 1. Create a Python venv
```bash
python -m venv venv
source venv/bin/activate   # or venv\Scripts\activate on Windows
```

### 2. Install dependencies
```bash
pip install -r requirements.txt
```
If you donâ€™t have `requirements.txt`, install manually:
```bash
pip install fastapi uvicorn diffusers transformers torch torchvision python-dotenv
```

### 3. Create `.env` file (backend)
```env
FRONTEND_ORIGIN=http://localhost:5173
SD_MODEL_ID=runwayml/stable-diffusion-v1-5
```

### 4. Run backend
```bash
uvicorn main:app --reload
```

Backend will run at: [http://127.0.0.1:8000](http://127.0.0.1:8000)

---

## ğŸ§‘â€ğŸ¨ Frontend Setup (Vite + React)

```bash
cd ai-image-frontend
npm install
```

Create `.env` inside `ai-image-frontend`:
```env
VITE_API_URL=http://127.0.0.1:8000
```

Run frontend:
```bash
npm run dev
```
Open: [http://localhost:5173](http://localhost:5173)

---

## ğŸ” Do Not Commit These!

Make sure you **add this to `.gitignore`**:
```gitignore
.env
venv/
__pycache__/
node_modules/
generated_image.png
```

---

## ğŸ§ª Test GPU
If you want to confirm PyTorch is using your GPU:
```python
import torch
print(torch.cuda.is_available())  # Should be True
print(torch.cuda.get_device_name())
```

---

## ğŸ“¸ Screenshot

### ğŸŸ¢ 1. Backend Started Successfully
Backend running with Stable Diffusion model loaded.

![Backend Startup](screenshots/backend-startup.png)

---

### ğŸŸ£ 2. Prompt Entered in Frontend
User enters a creative prompt like:
`a close-up portrait of a fluffy white cat with blue eyes, high-resolution, 4k`

![Frontend Prompt](screenshots/frontend-prompt.png)

---

### â³ 3. Image is Generating...
Frontend loading state while backend processes the image.

![Loading State](screenshots/loading-state.png)

---

### ğŸ–¼ï¸ 4. Final Image Displayed
The generated image is displayed after the request completes.

![Final Result](screenshots/final-result.png)

---

## ğŸ“„ License
MIT â€” use it freely, modify it proudly.

---

## ğŸ™Œ Acknowledgements
- [Hugging Face](https://huggingface.co/)
- [Diffusers](https://github.com/huggingface/diffusers)
- [FastAPI](https://fastapi.tiangolo.com)
- [React + Vite](https://vitejs.dev)

---

Built with â¤ï¸ by [@Viole07](https://github.com/Viole07)
